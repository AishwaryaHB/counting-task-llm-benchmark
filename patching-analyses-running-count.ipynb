{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17d1884e-1313-41e1-b97f-452aaeb9b54a",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d56f38b8-3c27-4a0b-b0b7-8a2c6a22a32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patching Analysis: Word Counting Task\n",
    "# Investigating whether a model (Falcon-7B-Instruct) maintains internal running count representations\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from nnsight import LanguageModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b536396-4ec6-4094-8889-16497144954f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef48180-a09d-4788-bf0f-f28c6acad1ae",
   "metadata": {},
   "source": [
    "#### Load dataset and benchmarking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9fabf7d-30a7-42b7-b32a-997b6df2f5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Dataset size: 5000 examples\n",
      "Results size: 20000 evaluations\n"
     ]
    }
   ],
   "source": [
    "# Load the original dataset\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"Load JSONL file\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return data\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "dataset = load_jsonl('word_counting_dataset.jsonl')\n",
    "results_df = pd.read_csv('evaluation_results_20250531_030418.csv')\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)} examples\")\n",
    "print(f\"Results size: {len(results_df)} evaluations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a87332f6-d9e3-400c-b469-07b91bae6ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First example from dataset:\n",
      "{'type': 'sports', 'list': ['book', 'tennis', 'soccer', 'cycling', 'apple', 'boxing', 'golf', 'chair', 'peach', 'horse', 'tennis'], 'answer': 4}\n",
      "\n",
      "First row from results:\n",
      "example_id                                           0\n",
      "type                                            sports\n",
      "list_length                                         11\n",
      "correct_answer                                       4\n",
      "raw_response                                        3)\n",
      "predicted_answer                                     3\n",
      "correct                                          False\n",
      "model               mistralai/Mistral-7B-Instruct-v0.3\n",
      "Name: 0, dtype: object\n",
      "\n",
      "Unique models in results:\n",
      "['mistralai/Mistral-7B-Instruct-v0.3' 'meta-llama/Llama-3.2-3B-Instruct'\n",
      " 'openai-community/gpt2-large' 'tiiuae/Falcon3-7B-Instruct']\n"
     ]
    }
   ],
   "source": [
    "# Explore the data structure\n",
    "print(\"\\nFirst example from dataset:\")\n",
    "print(dataset[0])\n",
    "\n",
    "print(\"\\nFirst row from results:\")\n",
    "print(results_df.iloc[0])\n",
    "\n",
    "print(\"\\nUnique models in results:\")\n",
    "print(results_df['model'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df77c7d7-a0b9-4acd-8f58-4ac892a8bacc",
   "metadata": {},
   "source": [
    "#### Filter data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd0792a0-c303-479c-9213-22b97903adab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(example):\n",
    "    \"\"\"Create a formatted prompt for the word counting task\"\"\"\n",
    "    list_str = \" \".join(example['list'])\n",
    "    \n",
    "    prompt = f\"\"\"Count the number of words in the following list that match the given type, and put the numerical answer in parentheses.\n",
    "    Type: {example['type']}\n",
    "    List: [{list_str}]\n",
    "    Answer: (\"\"\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa7f11cd-1777-4d88-ba6d-7080f9322d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_running_count(example, position):\n",
    "    \"\"\"Calculate running count up to given position\"\"\"\n",
    "    target_type = example['type']\n",
    "    count = 0\n",
    "    \n",
    "    # Define category mappings (you may need to expand this)\n",
    "    category_mappings = {\n",
    "        'fruits': ['apple', 'banana', 'cherry', 'grape', 'mango', 'peach', 'watermelon', 'pineapple', 'strawberry'],\n",
    "        'animals': ['cat', 'dog', 'horse', 'rabbit', 'snake', 'tiger', 'elephant', 'penguin', 'dolphin', 'eagle', 'mouse', 'bird', 'cow'],\n",
    "        'cities': ['Paris', 'London', 'Tokyo', 'Berlin', 'Mumbai', 'Bangkok', 'Sydney', 'Rio', 'Toronto'],\n",
    "        'sports': ['tennis', 'soccer', 'cycling', 'boxing', 'golf', 'basketball', 'baseball', 'hockey', 'volleyball', 'swimming'],\n",
    "        'professions': ['doctor', 'teacher', 'lawyer', 'engineer', 'pilot', 'chef', 'nurse', 'architect', 'mechanic', 'firefighter']\n",
    "    }\n",
    "    \n",
    "    target_words = category_mappings.get(target_type, [])\n",
    "    \n",
    "    for i in range(min(position + 1, len(example['list']))):\n",
    "        if example['list'][i].lower() in target_words:\n",
    "            count += 1\n",
    "            \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fe2e963-8200-4e4a-91d4-8400516da588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for Falcon results only\n",
    "falcon_results = results_df[results_df['model'] == 'tiiuae/Falcon3-7B-Instruct'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec51f302-f49c-4937-972d-e67a015584f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falcon results: 5000 examples\n"
     ]
    }
   ],
   "source": [
    "print(f\"Falcon results: {len(falcon_results)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "567e4d09-f38e-4a26-8ff0-228c54fbb52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply filtering criteria\n",
    "filtered_indices = []\n",
    "filtered_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4176959f-a842-4fcb-974f-c94aa543999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in falcon_results.iterrows():\n",
    "    example_id = row['example_id']\n",
    "    \n",
    "    # Get corresponding example from dataset\n",
    "    if example_id < len(dataset):\n",
    "        example = dataset[example_id]\n",
    "        \n",
    "        # Apply filters\n",
    "        list_length = len(example['list'])\n",
    "        target_count = example['answer']\n",
    "        is_correct = row['correct']\n",
    "        \n",
    "        if (list_length <= 8 and \n",
    "            target_count in [3, 4, 5, 6] and \n",
    "            is_correct):\n",
    "            \n",
    "            filtered_indices.append(example_id)\n",
    "            filtered_data.append({\n",
    "                'example_id': example_id,\n",
    "                'example': example,\n",
    "                'list_length': list_length,\n",
    "                'target_count': target_count,\n",
    "                'falcon_prediction': row['predicted_answer']\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c798fe63-b8d2-4696-9245-74df707652b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered dataset: 514 examples\n",
      "Distribution by target count:\n",
      "{5: 137, 4: 150, 3: 150, 6: 77}\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nFiltered dataset: {len(filtered_data)} examples\")\n",
    "print(\"Distribution by target count:\")\n",
    "count_dist = defaultdict(int)\n",
    "for item in filtered_data:\n",
    "    count_dist[item['target_count']] += 1\n",
    "print(dict(count_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f143289-b5a3-47e0-a28f-a78635914832",
   "metadata": {},
   "source": [
    "#### Generate control pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9d4a320-992a-4e37-9f9e-715c51e2692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_running_count_at_positions(example):\n",
    "    \"\"\"Find running count at each position in the sequence\"\"\"\n",
    "    counts_by_position = {}\n",
    "    for pos in range(len(example['list'])):\n",
    "        counts_by_position[pos] = calculate_running_count(example, pos)\n",
    "    return counts_by_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cd043d8-b7f1-46c7-9d11-b9ca2b50d543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_control_pairs(filtered_data, pairs_per_condition=100):\n",
    "    \"\"\"Generate pairs for 2x2 control design\"\"\"\n",
    "    \n",
    "    # First, calculate running counts for all examples\n",
    "    print(\"Calculating running counts for all examples...\")\n",
    "    for item in tqdm(filtered_data):\n",
    "        item['running_counts'] = find_running_count_at_positions(item['example'])\n",
    "    \n",
    "    control_pairs = {\n",
    "        'same_count_same_pos': [],      # Positive Control 1\n",
    "        'same_count_diff_pos': [],      # Positive Control 2  \n",
    "        'diff_count_same_pos': [],      # Negative Control 1\n",
    "        'diff_count_diff_pos': []       # Negative Control 2\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nGenerating {pairs_per_condition} pairs for each control condition...\")\n",
    "    \n",
    "    # Generate pairs for each condition\n",
    "    max_attempts = len(filtered_data) * 10  # Prevent infinite loops\n",
    "    \n",
    "    for condition in control_pairs.keys():\n",
    "        attempts = 0\n",
    "        while len(control_pairs[condition]) < pairs_per_condition and attempts < max_attempts:\n",
    "            attempts += 1\n",
    "            \n",
    "            # Randomly select two examples\n",
    "            example1 = random.choice(filtered_data)\n",
    "            example2 = random.choice(filtered_data)\n",
    "            \n",
    "            if example1['example_id'] == example2['example_id']:\n",
    "                continue\n",
    "                \n",
    "            # Find valid position pairs based on condition\n",
    "            valid_pairs = []\n",
    "            \n",
    "            for pos1 in range(len(example1['example']['list'])):\n",
    "                for pos2 in range(len(example2['example']['list'])):\n",
    "                    count1 = example1['running_counts'][pos1]\n",
    "                    count2 = example2['running_counts'][pos2]\n",
    "                    \n",
    "                    if condition == 'same_count_same_pos':\n",
    "                        if count1 == count2 and pos1 == pos2 and count1 > 0:\n",
    "                            valid_pairs.append((pos1, pos2))\n",
    "                    elif condition == 'same_count_diff_pos':\n",
    "                        if count1 == count2 and pos1 != pos2 and count1 > 0:\n",
    "                            valid_pairs.append((pos1, pos2))\n",
    "                    elif condition == 'diff_count_same_pos':\n",
    "                        if count1 != count2 and pos1 == pos2 and min(count1, count2) > 0:\n",
    "                            valid_pairs.append((pos1, pos2))\n",
    "                    elif condition == 'diff_count_diff_pos':\n",
    "                        if count1 != count2 and pos1 != pos2 and min(count1, count2) > 0:\n",
    "                            valid_pairs.append((pos1, pos2))\n",
    "            \n",
    "            if valid_pairs:\n",
    "                pos1, pos2 = random.choice(valid_pairs)\n",
    "                pair = {\n",
    "                    'source_example': example1,\n",
    "                    'target_example': example2,\n",
    "                    'source_position': pos1,\n",
    "                    'target_position': pos2,\n",
    "                    'source_count': example1['running_counts'][pos1],\n",
    "                    'target_count': example2['running_counts'][pos2],\n",
    "                    'condition': condition\n",
    "                }\n",
    "                control_pairs[condition].append(pair)\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\nControl pairs generated:\")\n",
    "    for condition, pairs in control_pairs.items():\n",
    "        print(f\"{condition}: {len(pairs)} pairs\")\n",
    "        if len(pairs) > 0:\n",
    "            sample_pair = pairs[0]\n",
    "            print(f\"  Example: count {sample_pair['source_count']}@pos{sample_pair['source_position']} ‚Üí count {sample_pair['target_count']}@pos{sample_pair['target_position']}\")\n",
    "    \n",
    "    return control_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad9d7d8d-eeb6-45c9-85d5-bb755e0094ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating running counts for all examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 514/514 [00:00<00:00, 73216.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating 100 pairs for each control condition...\n",
      "\n",
      "Control pairs generated:\n",
      "same_count_same_pos: 100 pairs\n",
      "  Example: count 1@pos0 ‚Üí count 1@pos0\n",
      "same_count_diff_pos: 100 pairs\n",
      "  Example: count 2@pos1 ‚Üí count 2@pos4\n",
      "diff_count_same_pos: 100 pairs\n",
      "  Example: count 4@pos3 ‚Üí count 2@pos3\n",
      "diff_count_diff_pos: 100 pairs\n",
      "  Example: count 3@pos2 ‚Üí count 5@pos4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate control pairs\n",
    "control_pairs = generate_control_pairs(filtered_data, pairs_per_condition=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11759748-05fd-4757-b8c5-0065d83143fb",
   "metadata": {},
   "source": [
    "#### Load Falcon model with NNsight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5080c77a-6525-418f-9e20-fcdd573d66e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Falcon model with NNsight...\n",
      "‚úì Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Falcon model with NNsight...\")\n",
    "\n",
    "# Load model (NNsight handles device placement automatically)\n",
    "model = LanguageModel(\"tiiuae/Falcon3-7B-Instruct\")\n",
    "\n",
    "print(\"‚úì Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83d7ed7-3043-474d-92dc-7fd598f18c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test basic functionality\n",
    "test_example = filtered_data[0]['example']\n",
    "test_prompt = create_prompt(test_example)\n",
    "\n",
    "print(f\"\\nTest prompt: {test_prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40088729-a181-4e87-b773-7a866fed4331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Falcon model with NNsight...\n",
      "‚úì Model loaded successfully!\n",
      "\n",
      "Test prompt: Count the number of words in the following list that match the given type, and put the numerical answer in parentheses.\n",
      "    Type: fruits\n",
      "    List: [watermelon grape apple peach chef pineapple]\n",
      "    Answer: (\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8430fd4b1b494aa4931b4c2c176343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Model test successful!\n",
      "\n",
      "Model architecture:\n",
      "Number of layers: 28 (model.model.layers)\n"
     ]
    }
   ],
   "source": [
    "# Use the proper NNsight generate syntax\n",
    "with model.generate(test_prompt, max_new_tokens=5, scan=False, validate=False) as tracer:\n",
    "    pass\n",
    "\n",
    "print(\"‚úì Model test successful!\")\n",
    "\n",
    "# Inspect model architecture\n",
    "print(f\"\\nModel architecture:\")\n",
    "try:\n",
    "    # Try different possible layer access patterns for Falcon3\n",
    "    if hasattr(model, 'model') and hasattr(model.model, 'layers'):\n",
    "        layers = model.model.layers\n",
    "        print(f\"Number of layers: {len(layers)} (model.model.layers)\")\n",
    "        layer_access = \"model.layers\"\n",
    "    elif hasattr(model, 'transformer') and hasattr(model.transformer, 'h'):\n",
    "        layers = model.transformer.h\n",
    "        print(f\"Number of layers: {len(layers)} (model.transformer.h)\")\n",
    "        layer_access = \"transformer.h\"\n",
    "    else:\n",
    "        print(\"Exploring model structure...\")\n",
    "        for attr in ['model', 'transformer']:\n",
    "            if hasattr(model, attr):\n",
    "                submodel = getattr(model, attr)\n",
    "                for subattr in ['layers', 'h', 'decoder']:\n",
    "                    if hasattr(submodel, subattr):\n",
    "                        layers = getattr(submodel, subattr)\n",
    "                        if hasattr(layers, '__len__'):\n",
    "                            print(f\"Found {len(layers)} layers at {attr}.{subattr}\")\n",
    "                            layer_access = f\"{attr}.{subattr}\"\n",
    "                            break\n",
    "except Exception as e:\n",
    "    print(f\"Error inspecting architecture: {e}\")\n",
    "    # We'll detect this during the actual experiments\n",
    "    layer_access = \"unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8b5389-8b05-4a96-843f-91fbb342826f",
   "metadata": {},
   "source": [
    "#### Record clean activations (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f286f66-1140-4b37-8611-705cd6e6039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# CELL 5: Record Clean Activations (Baseline)\n",
    "# ===================================================================\n",
    "\n",
    "def record_clean_activations(model, examples, max_examples=50):\n",
    "    \"\"\"Record clean forward passes for baseline comparison\"\"\"\n",
    "    \n",
    "    print(f\"Recording clean activations for {min(max_examples, len(examples))} examples...\")\n",
    "    \n",
    "    clean_data = []\n",
    "    \n",
    "    for i, item in enumerate(tqdm(examples[:max_examples])):\n",
    "        example = item['example']\n",
    "        prompt = create_prompt(example)\n",
    "        \n",
    "        try:\n",
    "            # Store references to save activations\n",
    "            saved_activations = {}\n",
    "            saved_output = None\n",
    "            \n",
    "            with model.generate(prompt, max_new_tokens=5, scan=False, validate=False) as tracer:\n",
    "                # Store activations from all layers using correct pattern\n",
    "                for layer_idx in range(28):  # We know Falcon3 has 28 layers\n",
    "                    # Get hidden states from this layer using model.model.layers\n",
    "                    layer_output = model.model.layers[layer_idx].output\n",
    "                    # Save the proxy objects\n",
    "                    saved_activations[layer_idx] = layer_output[0].save()\n",
    "                \n",
    "                saved_output = model.generator.output.save()\n",
    "            \n",
    "            # Now access the saved values (outside the context)\n",
    "            final_activations = {}\n",
    "            for layer_idx in range(28):\n",
    "                # Check if it's a proxy with .value or a direct tensor\n",
    "                activation = saved_activations[layer_idx]\n",
    "                if hasattr(activation, 'value'):\n",
    "                    final_activations[layer_idx] = activation.value.detach().cpu()\n",
    "                else:\n",
    "                    final_activations[layer_idx] = activation.detach().cpu()\n",
    "                \n",
    "            # Handle output similarly\n",
    "            if hasattr(saved_output, 'value'):\n",
    "                final_output = saved_output.value\n",
    "            else:\n",
    "                final_output = saved_output\n",
    "                \n",
    "            clean_data.append({\n",
    "                'example_id': item['example_id'],\n",
    "                'prompt': prompt,\n",
    "                'output': final_output,\n",
    "                'activations': final_activations,\n",
    "                'target_count': item['target_count']\n",
    "            })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing example {i}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"‚úì Recorded {len(clean_data)} clean activations\")\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d7a2cdc-bce1-4f2a-b444-91fc13e8e4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting baseline activation recording...\n",
      "Recording clean activations for 5 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      " 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                    | 1/5 [00:02<00:11,  2.99s/it]Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      " 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                           | 2/5 [00:05<00:08,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  | 3/5 [00:08<00:05,  2.56s/it]Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà         | 4/5 [00:11<00:02,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:13<00:00,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Recorded 5 clean activations\n",
      "‚úì Baseline recording successful!\n",
      "Activation shape example: torch.Size([1, 48, 3072])\n",
      "Number of layers recorded: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Record baseline activations for a subset of examples\n",
    "print(\"Starting baseline activation recording...\")\n",
    "baseline_activations = record_clean_activations(model, filtered_data, max_examples=5)\n",
    "\n",
    "if len(baseline_activations) > 0:\n",
    "    print(f\"‚úì Baseline recording successful!\")\n",
    "    print(f\"Activation shape example: {baseline_activations[0]['activations'][0].shape}\")\n",
    "    print(f\"Number of layers recorded: {len(baseline_activations[0]['activations'])}\")\n",
    "else:\n",
    "    print(\"‚ùå No baseline activations recorded - check for errors above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d56ff4a5-5adf-4ded-ae0d-e48d07fe685e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examining model outputs from baseline recording:\n",
      "============================================================\n",
      "\n",
      "Example 1:\n",
      "Example ID: 4\n",
      "Target count: 5\n",
      "Prompt: Count the number of words in the following list that match the given type, and put the numerical answer in parentheses.\n",
      "    Type: fruits\n",
      "    List: [watermelon grape apple peach chef pineapple]\n",
      "    Answer: (\n",
      "Full response: Count the number of words in the following list that match the given type, and put the numerical answer in parentheses.\n",
      "    Type: fruits\n",
      "    List: [watermelon grape apple peach chef pineapple]\n",
      "    Answer: (5)\n",
      "\n",
      "<\n",
      "Predicted answer: 5 ‚úì\n",
      "----------------------------------------\n",
      "\n",
      "Example 2:\n",
      "Example ID: 14\n",
      "Target count: 5\n",
      "Prompt: Count the number of words in the following list that match the given type, and put the numerical answer in parentheses.\n",
      "    Type: professions\n",
      "    List: [Sydney chef basketball teacher doctor lawyer engineer]\n",
      "    Answer: (\n",
      "Full response: Count the number of words in the following list that match the given type, and put the numerical answer in parentheses.\n",
      "    Type: professions\n",
      "    List: [Sydney chef basketball teacher doctor lawyer engineer]\n",
      "    Answer: (5)\n",
      "\n",
      "<\n",
      "Predicted answer: 5 ‚úì\n",
      "----------------------------------------\n",
      "\n",
      "Example 3:\n",
      "Example ID: 23\n",
      "Target count: 4\n",
      "Prompt: Count the number of words in the following list that match the given type, and put the numerical answer in parentheses.\n",
      "    Type: fruits\n",
      "    List: [mechanic cherry pilot computer mango apple pineapple]\n",
      "    Answer: (\n",
      "Full response: Count the number of words in the following list that match the given type, and put the numerical answer in parentheses.\n",
      "    Type: fruits\n",
      "    List: [mechanic cherry pilot computer mango apple pineapple]\n",
      "    Answer: (4)\n",
      "Predicted answer: 4 ‚úì\n",
      "----------------------------------------\n",
      "\n",
      "Example 4:\n",
      "Example ID: 27\n",
      "Target count: 3\n",
      "Prompt: Count the number of words in the following list that match the given type, and put the numerical answer in parentheses.\n",
      "    Type: cities\n",
      "    List: [London engineer Paris book Toronto]\n",
      "    Answer: (\n",
      "Full response: Count the number of words in the following list that match the given type, and put the numerical answer in parentheses.\n",
      "    Type: cities\n",
      "    List: [London engineer Paris book Toronto]\n",
      "    Answer: (3)**\n",
      "<|\n",
      "Predicted answer: 3 ‚úì\n",
      "----------------------------------------\n",
      "\n",
      "Example 5:\n",
      "Example ID: 31\n",
      "Target count: 4\n",
      "Prompt: Count the number of words in the following list that match the given type, and put the numerical answer in parentheses.\n",
      "    Type: cities\n",
      "    List: [London Mumbai Paris Tokyo Sydney book]\n",
      "    Answer: (\n",
      "Full response: Count the number of words in the following list that match the given type, and put the numerical answer in parentheses.\n",
      "    Type: cities\n",
      "    List: [London Mumbai Paris Tokyo Sydney book]\n",
      "    Answer: (4)\n",
      "Predicted answer: 4 ‚úì\n",
      "----------------------------------------\n",
      "\n",
      "Summary:\n",
      "Total examples processed: 5\n",
      "Activation tensor shape: torch.Size([1, 48, 3072])\n",
      "Number of layers captured: 28\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Inspect Baseline Outputs\n",
    "# ===================================================================\n",
    "\n",
    "print(\"Examining model outputs from baseline recording:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, data in enumerate(baseline_activations):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Example ID: {data['example_id']}\")\n",
    "    print(f\"Target count: {data['target_count']}\")\n",
    "    \n",
    "    # Show the prompt\n",
    "    prompt = data['prompt']\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    \n",
    "    # Decode and show the output\n",
    "    output = data['output']\n",
    "    if hasattr(output, 'cpu'):\n",
    "        output = output.cpu()\n",
    "    \n",
    "    if torch.is_tensor(output):\n",
    "        tokens = output.tolist()\n",
    "        if isinstance(tokens[0], list):\n",
    "            tokens = tokens[0]  # Remove batch dimension if present\n",
    "    else:\n",
    "        tokens = output\n",
    "    \n",
    "    # Decode the full sequence\n",
    "    full_response = model.tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "    print(f\"Full response: {full_response}\")\n",
    "    \n",
    "    # Try to extract the answer\n",
    "    import re\n",
    "    answer_match = re.search(r'(\\d+)\\)', full_response)\n",
    "    if answer_match:\n",
    "        predicted_answer = int(answer_match.group(1))\n",
    "        correct = predicted_answer == data['target_count']\n",
    "        print(f\"Predicted answer: {predicted_answer} {'‚úì' if correct else '‚úó'}\")\n",
    "    else:\n",
    "        print(\"Could not extract numerical answer\")\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"Total examples processed: {len(baseline_activations)}\")\n",
    "print(f\"Activation tensor shape: {baseline_activations[0]['activations'][0].shape}\")\n",
    "print(f\"Number of layers captured: {len(baseline_activations[0]['activations'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e77c8a0-348a-4e97-ac99-f25391af5c0b",
   "metadata": {},
   "source": [
    "#### Expt 1: Which layers encode running count?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ced2621-1672-4371-bb80-38248710fba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "34b95735-3dd1-4dee-99e5-8644b362a71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing basic activation access...\n",
      "\n",
      "--- Example 1 ---\n",
      "Testing layer 5, position 0\n",
      "Prompt: Count the number of words in the following list that match the given type, and put the numerical ans...\n",
      "‚úì Activation shape: torch.Size([48, 3072])\n",
      "‚úì Output shape: torch.Size([1, 53])\n",
      "Response: ...ape apple peach chef pineapple]\n",
      "    Answer: (5)\n",
      "\n",
      "<\n",
      "‚úì Success!\n",
      "\n",
      "--- Example 2 ---\n",
      "Testing layer 5, position 0\n",
      "Prompt: Count the number of words in the following list that match the given type, and put the numerical ans...\n",
      "‚úì Activation shape: torch.Size([48, 3072])\n",
      "‚úì Output shape: torch.Size([1, 53])\n",
      "Response: ...teacher doctor lawyer engineer]\n",
      "    Answer: (5)\n",
      "\n",
      "<\n",
      "‚úì Success!\n",
      "\n",
      "If basic access works, we can try simple patching next...\n"
     ]
    }
   ],
   "source": [
    "# # ===================================================================\n",
    "# # CELL 6: Test Basic Activation Access (No Patching Yet)\n",
    "# # ===================================================================\n",
    "\n",
    "# def test_activation_access(model, example, layer_idx, position):\n",
    "#     \"\"\"Test if we can access activations at specific positions\"\"\"\n",
    "    \n",
    "#     prompt = create_prompt(example['example'])\n",
    "#     print(f\"Testing layer {layer_idx}, position {position}\")\n",
    "#     print(f\"Prompt: {prompt[:100]}...\")\n",
    "    \n",
    "#     with model.generate(prompt, max_new_tokens=5, scan=False, validate=False, pad_token_id=model.tokenizer.eos_token_id) as tracer:\n",
    "#         # Try to access the layer output\n",
    "#         layer_output = model.model.layers[layer_idx].output\n",
    "        \n",
    "#         # Try to access specific position\n",
    "#         batch_output = layer_output[0]  # Batch dimension\n",
    "#         position_output = batch_output[position]  # Position dimension\n",
    "        \n",
    "#         # Save the activation\n",
    "#         saved_activation = position_output.save()\n",
    "        \n",
    "#         # Also save the full output for comparison\n",
    "#         full_output = model.generator.output.save()\n",
    "    \n",
    "#     # Access the saved values\n",
    "#     if hasattr(saved_activation, 'value'):\n",
    "#         activation_value = saved_activation.value\n",
    "#     else:\n",
    "#         activation_value = saved_activation\n",
    "        \n",
    "#     if hasattr(full_output, 'value'):\n",
    "#         output_value = full_output.value\n",
    "#     else:\n",
    "#         output_value = full_output\n",
    "        \n",
    "#     print(f\"‚úì Activation shape: {activation_value.shape}\")\n",
    "#     print(f\"‚úì Output shape: {output_value.shape}\")\n",
    "    \n",
    "#     # Decode the output\n",
    "#     if hasattr(output_value, 'cpu'):\n",
    "#         tokens = output_value.cpu()\n",
    "#     else:\n",
    "#         tokens = output_value\n",
    "        \n",
    "#     if torch.is_tensor(tokens):\n",
    "#         token_list = tokens.tolist()\n",
    "#         if isinstance(token_list[0], list):\n",
    "#             token_list = token_list[0]\n",
    "#     else:\n",
    "#         token_list = tokens\n",
    "        \n",
    "#     response = model.tokenizer.decode(token_list, skip_special_tokens=True)\n",
    "#     print(f\"Response: ...{response[-50:]}\")\n",
    "    \n",
    "#     return activation_value, output_value\n",
    "\n",
    "# # Test activation access on a few examples\n",
    "# print(\"Testing basic activation access...\")\n",
    "\n",
    "# test_examples = filtered_data[:2]\n",
    "# test_layer = 5\n",
    "# test_position = 0\n",
    "\n",
    "# for i, example in enumerate(test_examples):\n",
    "#     print(f\"\\n--- Example {i+1} ---\")\n",
    "#     try:\n",
    "#         activation, output = test_activation_access(model, example, test_layer, test_position)\n",
    "#         print(\"‚úì Success!\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚úó Error: {e}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()\n",
    "#         break\n",
    "\n",
    "# print(\"\\nIf basic access works, we can try simple patching next...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cf019450-4f4e-4d9c-bc4f-96fa4af9fa18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing Within-Context Modification ===\n",
      "Testing modification at layer 5, position 20\n",
      "Clean answer: 5\n",
      "Modified answer: 5\n",
      "Expected: 5\n",
      "Clean: 5\n",
      "Modified: 5\n",
      "? No change - try different position\n"
     ]
    }
   ],
   "source": [
    "# # ===================================================================\n",
    "# # CELL 6: Working Activation Modification (FINALLY FIXED!)\n",
    "# # ===================================================================\n",
    "\n",
    "# def test_correct_modification(model, prompt, layer_idx, position):\n",
    "#     \"\"\"Test modification with correct tensor indexing\"\"\"\n",
    "    \n",
    "#     print(f\"Testing modification at layer {layer_idx}, position {position}\")\n",
    "    \n",
    "#     # Get clean output\n",
    "#     with model.generate(prompt, max_new_tokens=5, scan=False, validate=False, pad_token_id=model.tokenizer.eos_token_id) as tracer:\n",
    "#         clean_output = model.generator.output.save()\n",
    "    \n",
    "#     clean_answer = extract_clean_answer(model, clean_output)\n",
    "#     print(f\"Clean answer: {clean_answer}\")\n",
    "    \n",
    "#     # Now modify with correct indexing\n",
    "#     with model.generate(prompt, max_new_tokens=5, scan=False, validate=False, pad_token_id=model.tokenizer.eos_token_id) as tracer:\n",
    "#         layer_output = model.model.layers[layer_idx].output\n",
    "        \n",
    "#         # layer_output is tuple, first element is tensor [1, 48, 3072]\n",
    "#         hidden_states = layer_output[0]  # Get the tensor [1, 48, 3072]\n",
    "        \n",
    "#         # Now access [batch=0, position, hidden_dim]\n",
    "#         target_activation = hidden_states[0, position, :]  # Shape: [3072]\n",
    "        \n",
    "#         # Zero it out\n",
    "#         hidden_states[0, position, :] = torch.zeros_like(target_activation)\n",
    "        \n",
    "#         modified_output = model.generator.output.save()\n",
    "    \n",
    "#     modified_answer = extract_clean_answer(model, modified_output)\n",
    "#     print(f\"Modified answer: {modified_answer}\")\n",
    "    \n",
    "#     return clean_answer, modified_answer\n",
    "\n",
    "# def test_cross_example_patch(model, source_example, target_example, layer_idx, position):\n",
    "#     \"\"\"Test patching between examples with correct indexing\"\"\"\n",
    "    \n",
    "#     source_prompt = create_prompt(source_example['example'])\n",
    "#     target_prompt = create_prompt(target_example['example'])\n",
    "    \n",
    "#     print(f\"Cross-example patch: layer {layer_idx}, position {position}\")\n",
    "#     print(f\"Source count: {source_example['target_count']}\")\n",
    "#     print(f\"Target count: {target_example['target_count']}\")\n",
    "    \n",
    "#     # Get clean target output\n",
    "#     with model.generate(target_prompt, max_new_tokens=5, scan=False, validate=False, pad_token_id=model.tokenizer.eos_token_id) as tracer:\n",
    "#         clean_output = model.generator.output.save()\n",
    "    \n",
    "#     clean_answer = extract_clean_answer(model, clean_output)\n",
    "#     print(f\"Clean target answer: {clean_answer}\")\n",
    "    \n",
    "#     # Get source activation\n",
    "#     with model.generate(source_prompt, max_new_tokens=5, scan=False, validate=False, pad_token_id=model.tokenizer.eos_token_id) as tracer:\n",
    "#         source_layer = model.model.layers[layer_idx].output\n",
    "#         source_hidden = source_layer[0]  # [1, seq_len, hidden_dim]\n",
    "#         source_activation = source_hidden[0, position, :].save()  # [hidden_dim]\n",
    "    \n",
    "#     # Apply patch to target\n",
    "#     with model.generate(target_prompt, max_new_tokens=5, scan=False, validate=False, pad_token_id=model.tokenizer.eos_token_id) as tracer:\n",
    "#         target_layer = model.model.layers[layer_idx].output\n",
    "#         target_hidden = target_layer[0]  # [1, seq_len, hidden_dim]\n",
    "        \n",
    "#         # Get the saved activation value\n",
    "#         if hasattr(source_activation, 'value'):\n",
    "#             activation_value = source_activation.value\n",
    "#         else:\n",
    "#             activation_value = source_activation\n",
    "        \n",
    "#         # Apply patch\n",
    "#         target_hidden[0, position, :] = activation_value\n",
    "        \n",
    "#         patched_output = model.generator.output.save()\n",
    "    \n",
    "#     patched_answer = extract_clean_answer(model, patched_output)\n",
    "#     print(f\"Patched answer: {patched_answer}\")\n",
    "    \n",
    "#     return clean_answer, patched_answer\n",
    "\n",
    "# def extract_clean_answer(model, output):\n",
    "#     \"\"\"Extract answer from model output\"\"\"\n",
    "#     if hasattr(output, 'value'):\n",
    "#         tokens = output.value\n",
    "#     else:\n",
    "#         tokens = output\n",
    "        \n",
    "#     if hasattr(tokens, 'cpu'):\n",
    "#         tokens = tokens.cpu()\n",
    "    \n",
    "#     if torch.is_tensor(tokens):\n",
    "#         token_list = tokens.tolist()\n",
    "#         if isinstance(token_list[0], list):\n",
    "#             token_list = token_list[0]\n",
    "#     else:\n",
    "#         token_list = tokens\n",
    "    \n",
    "#     response = model.tokenizer.decode(token_list, skip_special_tokens=True)\n",
    "    \n",
    "#     import re\n",
    "#     prompt_end = response.find(\"Answer: (\")\n",
    "#     if prompt_end != -1:\n",
    "#         answer_part = response[prompt_end + len(\"Answer: (\"):]\n",
    "#         match = re.search(r'^(\\d+)', answer_part)\n",
    "#         if match:\n",
    "#             return int(match.group(1))\n",
    "    \n",
    "#     return -1\n",
    "\n",
    "# # Test within-context modification\n",
    "# print(\"=== Testing Within-Context Modification ===\")\n",
    "# test_example = filtered_data[0]\n",
    "# test_prompt = create_prompt(test_example['example'])\n",
    "\n",
    "# clean_ans, modified_ans = test_correct_modification(model, test_prompt, 5, 20)\n",
    "\n",
    "# print(f\"Expected: {test_example['target_count']}\")\n",
    "# print(f\"Clean: {clean_ans}\")\n",
    "# print(f\"Modified: {modified_ans}\")\n",
    "\n",
    "# if modified_ans != clean_ans:\n",
    "#     print(\"‚úì Within-context modification works!\")\n",
    "    \n",
    "#     # Test cross-example patching\n",
    "#     print(\"\\n=== Testing Cross-Example Patching ===\")\n",
    "#     source_example = filtered_data[0]\n",
    "#     target_example = filtered_data[1]\n",
    "    \n",
    "#     try:\n",
    "#         clean_target, patched_target = test_cross_example_patch(model, source_example, target_example, 5, 20)\n",
    "        \n",
    "#         if patched_target != clean_target:\n",
    "#             print(\"‚úì Cross-example patching works!\")\n",
    "#             print(\"üéâ Ready for full layer analysis!\")\n",
    "#         else:\n",
    "#             print(\"? Patching didn't change answer - may need different position\")\n",
    "            \n",
    "#     except Exception as e:\n",
    "#         print(f\"Cross-example patching failed: {e}\")\n",
    "        \n",
    "# else:\n",
    "#     print(\"? No change - try different position\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d86a314d-27d7-468a-9048-7cc3f9a8f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_layer_patch(model, source_example, target_example, source_pos, target_pos, layer_idx):\n",
    "    \"\"\"Patch a single layer between two examples - WORKING VERSION\"\"\"\n",
    "    \n",
    "    source_prompt = create_prompt(source_example['example'])\n",
    "    target_prompt = create_prompt(target_example['example'])\n",
    "    \n",
    "    # Get clean target output\n",
    "    with model.generate(target_prompt, max_new_tokens=5, scan=False, validate=False, pad_token_id=model.tokenizer.eos_token_id) as tracer:\n",
    "        clean_output = model.generator.output.save()\n",
    "    \n",
    "    # Get source activation\n",
    "    with model.generate(source_prompt, max_new_tokens=5, scan=False, validate=False, pad_token_id=model.tokenizer.eos_token_id) as tracer:\n",
    "        source_layer = model.model.layers[layer_idx].output\n",
    "        source_hidden = source_layer[0]  # [1, seq_len, hidden_dim]\n",
    "        source_activation = source_hidden[0, source_pos, :].save()  # [hidden_dim]\n",
    "    \n",
    "    # Apply patch to target\n",
    "    with model.generate(target_prompt, max_new_tokens=5, scan=False, validate=False, pad_token_id=model.tokenizer.eos_token_id) as tracer:\n",
    "        target_layer = model.model.layers[layer_idx].output\n",
    "        target_hidden = target_layer[0]  # [1, seq_len, hidden_dim]\n",
    "        \n",
    "        # Apply patch\n",
    "        if hasattr(source_activation, 'value'):\n",
    "            activation_value = source_activation.value\n",
    "        else:\n",
    "            activation_value = source_activation\n",
    "            \n",
    "        target_hidden[0, target_pos, :] = activation_value\n",
    "        \n",
    "        patched_output = model.generator.output.save()\n",
    "    \n",
    "    return {\n",
    "        'clean_output': clean_output,\n",
    "        'patched_output': patched_output,\n",
    "        'source_prompt': source_prompt,\n",
    "        'target_prompt': target_prompt\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c60753d2-05b0-43fd-833e-f7f30021a8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer_from_output(model, output):\n",
    "    \"\"\"Extract numerical answer from model output\"\"\"\n",
    "    if hasattr(output, 'value'):\n",
    "        tokens = output.value\n",
    "    else:\n",
    "        tokens = output\n",
    "        \n",
    "    if hasattr(tokens, 'cpu'):\n",
    "        tokens = tokens.cpu()\n",
    "    \n",
    "    if torch.is_tensor(tokens):\n",
    "        token_list = tokens.tolist()\n",
    "        if isinstance(token_list[0], list):\n",
    "            token_list = token_list[0]\n",
    "    else:\n",
    "        token_list = tokens\n",
    "    \n",
    "    response = model.tokenizer.decode(token_list, skip_special_tokens=True)\n",
    "    \n",
    "    import re\n",
    "    prompt_end = response.find(\"Answer: (\")\n",
    "    if prompt_end != -1:\n",
    "        answer_part = response[prompt_end + len(\"Answer: (\"):]\n",
    "        match = re.search(r'^(\\d+)', answer_part)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "    \n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a0574b4f-4dee-4212-a1e2-bafd34a6d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_layer_effectiveness(model, control_pairs, test_layers, test_positions, max_pairs=5):\n",
    "    \"\"\"Test which layers and positions are most effective for patching\"\"\"\n",
    "    \n",
    "    print(\"Testing layer effectiveness...\")\n",
    "    \n",
    "    # Use positive control pairs (same count, same position)\n",
    "    test_pairs = control_pairs['same_count_same_pos'][:max_pairs]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for layer_idx in test_layers:\n",
    "        print(f\"\\n--- Testing Layer {layer_idx} ---\")\n",
    "        \n",
    "        for position in test_positions:\n",
    "            layer_results = []\n",
    "            \n",
    "            for pair_idx, pair in enumerate(test_pairs):\n",
    "                try:\n",
    "                    result = single_layer_patch(\n",
    "                        model,\n",
    "                        pair['source_example'],\n",
    "                        pair['target_example'], \n",
    "                        position,  # Use same position for both\n",
    "                        position,\n",
    "                        layer_idx\n",
    "                    )\n",
    "                    \n",
    "                    # Extract answers\n",
    "                    clean_answer = extract_answer_from_output(model, result['clean_output'])\n",
    "                    patched_answer = extract_answer_from_output(model, result['patched_output'])\n",
    "                    \n",
    "                    target_correct_answer = pair['target_example']['target_count']\n",
    "                    accuracy_preserved = (patched_answer == target_correct_answer)\n",
    "                    \n",
    "                    layer_results.append(accuracy_preserved)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"      Error: {e}\")\n",
    "                    layer_results.append(False)\n",
    "            \n",
    "            if layer_results:\n",
    "                success_rate = sum(layer_results) / len(layer_results)\n",
    "                print(f\"  Position {position}: {success_rate:.1%} accuracy preservation ({sum(layer_results)}/{len(layer_results)})\")\n",
    "                \n",
    "                results.append({\n",
    "                    'layer': layer_idx,\n",
    "                    'position': position,\n",
    "                    'success_rate': success_rate,\n",
    "                    'successes': sum(layer_results),\n",
    "                    'total': len(layer_results)\n",
    "                })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dd75cf-9ab3-4849-b224-120d203a641b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding effective intervention points...\n",
      "Testing layer effectiveness...\n",
      "\n",
      "--- Testing Layer 2 ---\n",
      "  Position 5: 100.0% accuracy preservation (3/3)\n",
      "  Position 10: 100.0% accuracy preservation (3/3)\n",
      "  Position 15: 100.0% accuracy preservation (3/3)\n",
      "  Position 20: 100.0% accuracy preservation (3/3)\n",
      "  Position 25: 100.0% accuracy preservation (3/3)\n",
      "  Position 30: 100.0% accuracy preservation (3/3)\n",
      "\n",
      "--- Testing Layer 5 ---\n",
      "  Position 5: 100.0% accuracy preservation (3/3)\n",
      "  Position 10: 100.0% accuracy preservation (3/3)\n",
      "  Position 15: 100.0% accuracy preservation (3/3)\n",
      "  Position 20: 100.0% accuracy preservation (3/3)\n",
      "  Position 25: 100.0% accuracy preservation (3/3)\n",
      "  Position 30: 100.0% accuracy preservation (3/3)\n",
      "\n",
      "--- Testing Layer 10 ---\n",
      "  Position 5: 100.0% accuracy preservation (3/3)\n",
      "  Position 10: 100.0% accuracy preservation (3/3)\n",
      "  Position 15: 100.0% accuracy preservation (3/3)\n",
      "  Position 20: 100.0% accuracy preservation (3/3)\n",
      "  Position 25: 100.0% accuracy preservation (3/3)\n",
      "  Position 30: 100.0% accuracy preservation (3/3)\n",
      "\n",
      "--- Testing Layer 15 ---\n",
      "  Position 5: 100.0% accuracy preservation (3/3)\n",
      "  Position 10: 100.0% accuracy preservation (3/3)\n",
      "  Position 15: 100.0% accuracy preservation (3/3)\n",
      "  Position 20: 100.0% accuracy preservation (3/3)\n",
      "  Position 25: 100.0% accuracy preservation (3/3)\n",
      "  Position 30: 100.0% accuracy preservation (3/3)\n",
      "\n",
      "--- Testing Layer 20 ---\n",
      "  Position 5: 100.0% accuracy preservation (3/3)\n",
      "  Position 10: 100.0% accuracy preservation (3/3)\n"
     ]
    }
   ],
   "source": [
    "# Test effectiveness across multiple layers and positions\n",
    "print(\"Finding effective intervention points...\")\n",
    "\n",
    "# Test a range of layers (early, middle, late)\n",
    "test_layers = [2, 5, 10, 15, 20, 25]\n",
    "\n",
    "# Test key positions in the sequence\n",
    "test_positions = [5, 10, 15, 20, 25, 30]\n",
    "\n",
    "# Run the effectiveness test\n",
    "effectiveness_results = test_layer_effectiveness(\n",
    "    model, \n",
    "    control_pairs, \n",
    "    test_layers, \n",
    "    test_positions, \n",
    "    max_pairs=3  # Small number for fast testing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86d5794-6cbb-40a8-b687-1529aea2b209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze results\n",
    "print(f\"\\n=== EFFECTIVENESS ANALYSIS ===\")\n",
    "\n",
    "if effectiveness_results:\n",
    "    # Sort by success rate\n",
    "    sorted_results = sorted(effectiveness_results, key=lambda x: x['success_rate'], reverse=True)\n",
    "    \n",
    "    print(\"Top 5 most effective intervention points:\")\n",
    "    for i, result in enumerate(sorted_results[:5]):\n",
    "        print(f\"{i+1}. Layer {result['layer']}, Position {result['position']}: {result['success_rate']:.1%}\")\n",
    "    \n",
    "    # Find best layers\n",
    "    layer_scores = {}\n",
    "    for result in effectiveness_results:\n",
    "        layer = result['layer']\n",
    "        if layer not in layer_scores:\n",
    "            layer_scores[layer] = []\n",
    "        layer_scores[layer].append(result['success_rate'])\n",
    "    \n",
    "    print(f\"\\nBest layers (average across positions):\")\n",
    "    for layer in sorted(layer_scores.keys()):\n",
    "        avg_score = sum(layer_scores[layer]) / len(layer_scores[layer])\n",
    "        print(f\"  Layer {layer}: {avg_score:.1%}\")\n",
    "    \n",
    "    # Recommend top layers for full analysis\n",
    "    best_layers = sorted(layer_scores.keys(), key=lambda l: sum(layer_scores[l])/len(layer_scores[l]), reverse=True)[:3]\n",
    "    print(f\"\\nüéØ Recommended layers for full analysis: {best_layers}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No successful interventions found. May need to:\")\n",
    "    print(\"- Try different layers\")\n",
    "    print(\"- Use different positions\") \n",
    "    print(\"- Check if the control pairs are appropriate\")\n",
    "\n",
    "print(f\"\\n‚úÖ Cell 6 prototype complete! Patching pipeline is working.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dddc7cf-43fc-4010-89db-42a95027626d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81d61f1-5625-493b-b80e-e868e9580dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2553c97-1e35-46a8-bfa2-51b9b1a0d626",
   "metadata": {},
   "source": [
    "#### Cell 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102f06b9-5677-429a-9b90-90b5a630b53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# CELL 7: Test All 4 Controls (Full 2x2 Analysis)\n",
    "# ===================================================================\n",
    "\n",
    "def test_all_controls(model, control_pairs, test_layers, test_position, max_pairs=5):\n",
    "    \"\"\"Test all 4 control conditions to see the real differences\"\"\"\n",
    "    \n",
    "    print(f\"Testing all 4 controls at position {test_position}...\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    control_names = {\n",
    "        'same_count_same_pos': 'Positive Control 1 (same count, same position)',\n",
    "        'same_count_diff_pos': 'Positive Control 2 (same count, different position)', \n",
    "        'diff_count_same_pos': 'Negative Control 1 (different count, same position)',\n",
    "        'diff_count_diff_pos': 'Negative Control 2 (different count, different position)'\n",
    "    }\n",
    "    \n",
    "    for control_type, pairs in control_pairs.items():\n",
    "        if len(pairs) == 0:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n--- {control_names[control_type]} ---\")\n",
    "        test_pairs = pairs[:max_pairs]\n",
    "        \n",
    "        control_results = {}\n",
    "        \n",
    "        for layer_idx in test_layers:\n",
    "            layer_successes = []\n",
    "            \n",
    "            for pair in test_pairs:\n",
    "                try:\n",
    "                    # Use the actual positions from the pair for different position tests\n",
    "                    if 'diff_pos' in control_type:\n",
    "                        src_pos = pair['source_position'] \n",
    "                        tgt_pos = pair['target_position']\n",
    "                    else:\n",
    "                        src_pos = test_position\n",
    "                        tgt_pos = test_position\n",
    "                    \n",
    "                    result = single_layer_patch(\n",
    "                        model,\n",
    "                        pair['source_example'],\n",
    "                        pair['target_example'],\n",
    "                        src_pos,\n",
    "                        tgt_pos, \n",
    "                        layer_idx\n",
    "                    )\n",
    "                    \n",
    "                    clean_answer = extract_answer_from_output(model, result['clean_output'])\n",
    "                    patched_answer = extract_answer_from_output(model, result['patched_output'])\n",
    "                    \n",
    "                    target_correct = pair['target_example']['target_count']\n",
    "                    accuracy_preserved = (patched_answer == target_correct)\n",
    "                    layer_successes.append(accuracy_preserved)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"    Layer {layer_idx} error: {e}\")\n",
    "                    layer_successes.append(False)\n",
    "            \n",
    "            if layer_successes:\n",
    "                success_rate = sum(layer_successes) / len(layer_successes)\n",
    "                control_results[layer_idx] = success_rate\n",
    "                print(f\"  Layer {layer_idx}: {success_rate:.1%}\")\n",
    "        \n",
    "        results[control_type] = control_results\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test all controls on a few key layers\n",
    "key_layers = [5, 10, 15, 20]  # Middle layers most likely to be important\n",
    "test_position = 15  # Safe position that should exist in most sequences\n",
    "\n",
    "all_results = test_all_controls(model, control_pairs, key_layers, test_position, max_pairs=3)\n",
    "\n",
    "# Analyze the pattern\n",
    "print(f\"\\n=== CONTROL COMPARISON ===\")\n",
    "for layer in key_layers:\n",
    "    print(f\"\\nLayer {layer}:\")\n",
    "    for control_type, results in all_results.items():\n",
    "        if layer in results:\n",
    "            rate = results[layer]\n",
    "            print(f\"  {control_type}: {rate:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4112cdd-517c-4dea-963c-518d36da9268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91589cb7-15dc-435d-8fe1-0c62a3cf7cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea03fc01-2e1d-4000-b5c0-ca772a6ad789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cd8b68-4ece-4f58-b1fc-dcb42f259fda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94569976-3006-4b37-a31d-f0ca502beb49",
   "metadata": {},
   "source": [
    "#### Visualize layer effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedbf1e7-9562-4e72-a78c-94578c4919bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot layer criticality\n",
    "plt.figure(figsize=(12, 6))\n",
    "layers = list(layer_effects.keys())\n",
    "effects = list(layer_effects.values())\n",
    "\n",
    "plt.plot(layers, effects, 'b-o', linewidth=2, markersize=6)\n",
    "plt.xlabel('Layer Index')\n",
    "plt.ylabel('Accuracy Preservation Rate')\n",
    "plt.title('Layer Criticality for Count Representation\\n(Higher = More Critical)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Highlight top layers\n",
    "top_layers = sorted(layer_effects.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "for layer_idx, effect in top_layers:\n",
    "    plt.annotate(f'L{layer_idx}: {effect:.3f}', \n",
    "                xy=(layer_idx, effect), \n",
    "                xytext=(5, 5), \n",
    "                textcoords='offset points',\n",
    "                fontsize=8,\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8372ca-6205-4768-97c2-6707d16146ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 5 most critical layers:\")\n",
    "for i, (layer_idx, effect) in enumerate(top_layers):\n",
    "    print(f\"{i+1}. Layer {layer_idx}: {effect:.3f} accuracy preservation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfb899c-0de3-42ee-b36c-d536f80e84d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 3 layers for detailed analysis\n",
    "critical_layers = [layer for layer, _ in top_layers[:3]]\n",
    "print(f\"\\nSelected critical layers for detailed analysis: {critical_layers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e932aa9-6445-4421-83c8-e68ca21b85b4",
   "metadata": {},
   "source": [
    "#### 2x2 control matrix analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7d9259-51f5-45ae-a99a-9b5c6610392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_2x2_analysis(model, control_pairs, critical_layers, max_pairs=20):\n",
    "    \"\"\"Run the full 2x2 control matrix analysis\"\"\"\n",
    "    \n",
    "    print(\"Running 2x2 control matrix analysis...\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for condition in control_pairs.keys():\n",
    "        print(f\"\\nTesting condition: {condition}\")\n",
    "        condition_results = {}\n",
    "        \n",
    "        for layer_idx in critical_layers:\n",
    "            print(f\"  Layer {layer_idx}...\")\n",
    "            \n",
    "            test_pairs = control_pairs[condition][:max_pairs]\n",
    "            accuracy_scores = []\n",
    "            \n",
    "            for pair in tqdm(test_pairs, desc=f\"Layer {layer_idx}\"):\n",
    "                try:\n",
    "                    result = single_layer_patch(\n",
    "                        model,\n",
    "                        pair['source_example'],\n",
    "                        pair['target_example'],\n",
    "                        pair['source_position'], \n",
    "                        pair['target_position'],\n",
    "                        layer_idx\n",
    "                    )\n",
    "                    \n",
    "                    # Extract answers\n",
    "                    clean_answer = extract_answer_from_output(model, result['clean_output'])\n",
    "                    patched_answer = extract_answer_from_output(model, result['patched_output'])\n",
    "                    \n",
    "                    # Check if patching preserved accuracy\n",
    "                    target_correct = pair['target_example']['target_count']\n",
    "                    accuracy_preserved = (patched_answer == target_correct)\n",
    "                    accuracy_scores.append(accuracy_preserved)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    accuracy_scores.append(False)\n",
    "            \n",
    "            condition_results[layer_idx] = np.mean(accuracy_scores)\n",
    "            print(f\"    Accuracy preservation: {condition_results[layer_idx]:.3f}\")\n",
    "        \n",
    "        results[condition] = condition_results\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c29331-c7d5-4a46-a293-90eaacf04306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 2x2 analysis\n",
    "matrix_results = run_2x2_analysis(model, control_pairs, critical_layers, max_pairs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff84841-fe50-4762-88b5-8b183b1a106d",
   "metadata": {},
   "source": [
    "#### Visualize 2x2 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d15285d-2a98-4bb6-8fec-67f511669c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2x2 heatmap for each critical layer\n",
    "fig, axes = plt.subplots(1, len(critical_layers), figsize=(5*len(critical_layers), 4))\n",
    "if len(critical_layers) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, layer_idx in enumerate(critical_layers):\n",
    "    # Extract data for this layer\n",
    "    data_matrix = np.array([\n",
    "        [matrix_results['same_count_same_pos'][layer_idx], matrix_results['same_count_diff_pos'][layer_idx]],\n",
    "        [matrix_results['diff_count_same_pos'][layer_idx], matrix_results['diff_count_diff_pos'][layer_idx]]\n",
    "    ])\n",
    "    \n",
    "    # Create heatmap\n",
    "    sns.heatmap(data_matrix, \n",
    "                annot=True, \n",
    "                fmt='.3f', \n",
    "                cmap='RdYlGn',\n",
    "                vmin=0, vmax=1,\n",
    "                xticklabels=['Same Position', 'Different Position'],\n",
    "                yticklabels=['Same Count', 'Different Count'],\n",
    "                ax=axes[i])\n",
    "    \n",
    "    axes[i].set_title(f'Layer {layer_idx}\\nAccuracy Preservation')\n",
    "    axes[i].set_xlabel('Position Match')\n",
    "    axes[i].set_ylabel('Count Match')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7133fd2b-fca3-4cbf-8857-2ae5c6c05a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY: 2x2 Control Matrix Results\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20696842-10d0-4404-9d12-ec9a2f6d3d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.DataFrame(matrix_results).round(3)\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcde0a9-c164-4d3b-a8be-be4e3c388041",
   "metadata": {},
   "source": [
    "#### Interpret results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac1d31d-ce5b-48f6-9b7b-a6f7cc4fab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INTERPRETATION OF RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Analyze the pattern\n",
    "avg_results = {}\n",
    "for condition in matrix_results.keys():\n",
    "    avg_results[condition] = np.mean(list(matrix_results[condition].values()))\n",
    "\n",
    "print(f\"Average accuracy preservation across layers:\")\n",
    "for condition, avg_acc in avg_results.items():\n",
    "    print(f\"  {condition}: {avg_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df712ea8-8b5c-4f69-90b6-911f0f73baa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key comparisons\n",
    "same_count_same_pos = avg_results['same_count_same_pos']\n",
    "same_count_diff_pos = avg_results['same_count_diff_pos'] \n",
    "diff_count_same_pos = avg_results['diff_count_same_pos']\n",
    "diff_count_diff_pos = avg_results['diff_count_diff_pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03adc947-b46f-48f6-b01e-61b1f05bb99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nKey Findings:\")\n",
    "\n",
    "print(f\"\\n1. Are count representations position-independent?\")\n",
    "if same_count_diff_pos > 0.5:\n",
    "    print(f\"   YES: Same count + different position works well ({same_count_diff_pos:.3f})\")\n",
    "    print(f\"   This suggests count representations are somewhat position-independent\")\n",
    "else:\n",
    "    print(f\"   NO: Same count + different position fails ({same_count_diff_pos:.3f})\")\n",
    "    print(f\"   This suggests count representations are position-specific\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367ee83a-cc14-4815-9424-1aec50ac36d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n2. What matters more: count match or position match?\")\n",
    "count_effect = same_count_same_pos - diff_count_same_pos\n",
    "position_effect = same_count_same_pos - same_count_diff_pos\n",
    "\n",
    "print(f\"   Count match effect: {count_effect:.3f}\")\n",
    "print(f\"   Position match effect: {position_effect:.3f}\")\n",
    "\n",
    "if count_effect > position_effect:\n",
    "    print(f\"   Count matching is more important than position matching\")\n",
    "else:\n",
    "    print(f\"   Position matching is more important than count matching\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4a186f-49b0-42ea-8498-414a4979fec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n3. Which layers are most critical?\")\n",
    "best_layer = max(critical_layers, key=lambda l: matrix_results['same_count_same_pos'][l])\n",
    "print(f\"   Layer {best_layer} shows strongest effects\")\n",
    "print(f\"   This suggests layer {best_layer} is most important for count representation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fac2403-6cc8-4259-a97b-10ff25a218e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n4. Overall assessment:\")\n",
    "if same_count_same_pos > 0.7:\n",
    "    print(f\"   STRONG evidence for internal count representations\")\n",
    "elif same_count_same_pos > 0.5:\n",
    "    print(f\"   MODERATE evidence for internal count representations\") \n",
    "else:\n",
    "    print(f\"   WEAK evidence for internal count representations\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"Analysis complete! üéâ\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11af7feb-be61-4c8a-a2e9-9e6ea1d52fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f0dc0b-313d-494c-aacf-8cf859da5c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b82c3f-18e1-4301-a46f-7596e8d73ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
